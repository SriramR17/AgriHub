{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.document_loaders import PyPDFLoader , DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDF'S Loaded\n"
     ]
    }
   ],
   "source": [
    "data_path = r\"D:\\agribot\\datas/\"\n",
    "dir_loader = DirectoryLoader(\n",
    "    data_path,\n",
    "    glob='*.pdf',\n",
    "    loader_cls=PyPDFLoader\n",
    ")\n",
    "docs = dir_loader.load()\n",
    "print(\"PDF'S Loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Chunks Created\n"
     ]
    }
   ],
   "source": [
    "txt_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 1000,\n",
    "    chunk_overlap = 500\n",
    ")\n",
    "inp_txt = txt_splitter.split_documents(docs)\n",
    "print(\"Data Chunks Created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90775d645bd94daf910407a9ba73da09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/670M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "733d98b438674e748c95e4ece10b0c9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/342 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78b0346d3ba34a7f907547e2df4bf542",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20a681d57d824cd296b09b87785892ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/712k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53f8abc59009417e87c15e05a8a51074",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e58f5d7b720439b955db6c2a8290dbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "1_Pooling/config.json:   0%|          | 0.00/191 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding Created\n"
     ]
    }
   ],
   "source": [
    "hfembeddings = HuggingFaceEmbeddings(\n",
    "    model_name = \"thenlper/gte-large\",\n",
    "    model_kwargs = {'device':'cuda'}\n",
    ")\n",
    "print(\"Embedding Created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\newenv\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:435: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at ..\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:455.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector Store Creation Completed and Stored Locally\n"
     ]
    }
   ],
   "source": [
    "db = FAISS.from_documents(inp_txt,hfembeddings)\n",
    "db.save_local(r\"D:\\agribot\\faiss\\agri_data\")\n",
    "print(\"Vector Store Creation Completed and Stored Locally\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **inference**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.llms import CTransformers , HuggingFaceHub\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT_TEMPLATE = '''\n",
    "With the information provided try to answer the question. \n",
    "If you cant answer the question based on the information either say you cant find an answer or unable to find an answer.\n",
    "So try to understand in depth about the context and answer only based on the information provided. Dont generate irrelevant answers\n",
    "\n",
    "Context: {context}\n",
    "Question: {question}\n",
    "Do provide only helpful answers\n",
    "\n",
    "Helpful answer:\n",
    "'''\n",
    "INP_VARS = ['context', 'question']\n",
    "custom_prompt_template = PromptTemplate(\n",
    "    template = PROMPT_TEMPLATE,\n",
    "    input_variables = INP_VARS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = CTransformers(\n",
    "    model = r\"D:\\agribot\\llama-2-7b-chat.ggmlv3.q4_1.bin\",\n",
    "    model_type=\"llama\",\n",
    "    max_new_tokens = 512,\n",
    "    temperature = 0.2,\n",
    "    callbacks=[StreamingStdOutCallbackHandler()],\n",
    "    gpu_layers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding Created\n"
     ]
    }
   ],
   "source": [
    "hfembeddings = HuggingFaceEmbeddings(\n",
    "    model_name = \"thenlper/gte-large\",\n",
    "    model_kwargs = {'device':'cuda'}\n",
    ")\n",
    "print(\"Embedding Created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_db = FAISS.load_local(r\"D:\\agribot\\faiss\\agri_data/\", hfembeddings,allow_dangerous_deserialization=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieval_qa_chain = RetrievalQA.from_chain_type(\n",
    "                                llm=llm,\n",
    "                                chain_type=\"stuff\",\n",
    "                                retriever=vector_db.as_retriever(search_kwargs={'k': 1}),\n",
    "                                return_source_documents=True,\n",
    "                                chain_type_kwargs={\"prompt\": custom_prompt_template}\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\newenv\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:119: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n",
      "d:\\newenv\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:435: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at ..\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:455.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The root system is the most important part of a plant for a farmer or plant grower. The root system absorbs water and nutrients from the soil, which are then transported throughout the plant to support growth and development. Without a healthy root system, a plant cannot survive, let alone thrive. While other parts of the plant, such as leaves, stems, and flowers, are important for photosynthesis and reproduction, they are dependent on the root system for water and nutrients. Therefore, it is crucial that farmers and plant growers prioritize the health and well-being of the root system in order to produce a bountiful harvest.The root system is the most important part of a plant for a farmer or plant grower. The root system absorbs water and nutrients from the soil, which are then transported throughout the plant to support growth and development. Without a healthy root system, a plant cannot survive, let alone thrive. While other parts of the plant, such as leaves, stems, and flowers, are important for photosynthesis and reproduction, they are dependent on the root system for water and nutrients. Therefore, it is crucial that farmers and plant growers prioritize the health and well-being of the root system in order to produce a bountiful harvest.\n"
     ]
    }
   ],
   "source": [
    "user_input = \"Which of the parts of the plant is of greatest importance to the farmer or any plant grower?\"\n",
    "prompt = {'query': user_input}\n",
    "model_out = retrieval_qa_chain(prompt)\n",
    "answer = model_out['result']\n",
    "print(answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
